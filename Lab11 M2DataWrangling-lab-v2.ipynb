{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Summarize the dataset\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Types:\n",
      "ResponseId               int64\n",
      "MainBranch              object\n",
      "Age                     object\n",
      "Employment              object\n",
      "RemoteWork              object\n",
      "                        ...   \n",
      "JobSatPoints_11        float64\n",
      "SurveyLength            object\n",
      "SurveyEase              object\n",
      "ConvertedCompYearly    float64\n",
      "JobSat                 float64\n",
      "Length: 114, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Summarize the dataset by displaying column data types\n",
    "print(\"Column Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary - Counts and Missing Values:\n",
      "ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10631\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summarize the dataset by displaying counts and missing values\n",
    "\n",
    "print(\"Dataset Summary - Counts and Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics for Numerical Columns:\n",
      "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Generate basic statistics for numerical columns\n",
    "print(\"Basic Statistics for Numerical Columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.000000</td>\n",
       "      <td>29324.000000</td>\n",
       "      <td>29393.000000</td>\n",
       "      <td>29411.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29448.00000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29445.000000</td>\n",
       "      <td>2.343500e+04</td>\n",
       "      <td>29126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.466957</td>\n",
       "      <td>18.581094</td>\n",
       "      <td>7.522140</td>\n",
       "      <td>10.060857</td>\n",
       "      <td>24.343232</td>\n",
       "      <td>22.96522</td>\n",
       "      <td>20.278165</td>\n",
       "      <td>16.169432</td>\n",
       "      <td>10.955713</td>\n",
       "      <td>9.953948</td>\n",
       "      <td>8.615529e+04</td>\n",
       "      <td>6.935041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18890.179119</td>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.168709</td>\n",
       "      <td>25.966221</td>\n",
       "      <td>18.422661</td>\n",
       "      <td>21.833836</td>\n",
       "      <td>27.089360</td>\n",
       "      <td>27.01774</td>\n",
       "      <td>26.108110</td>\n",
       "      <td>24.845032</td>\n",
       "      <td>22.906263</td>\n",
       "      <td>21.775652</td>\n",
       "      <td>1.867570e+05</td>\n",
       "      <td>2.088259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16360.000000</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271200e+04</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49078.000000</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.079715e+05</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.625660e+07</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
       "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
       "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
       "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
       "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
       "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
       "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
       "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
       "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
       "\n",
       "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
       "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
       "mean         7.522140       10.060857       24.343232        22.96522   \n",
       "std         18.422661       21.833836       27.089360        27.01774   \n",
       "min          0.000000        0.000000        0.000000         0.00000   \n",
       "25%          0.000000        0.000000        0.000000         0.00000   \n",
       "50%          0.000000        0.000000       20.000000        15.00000   \n",
       "75%          5.000000       10.000000       30.000000        30.00000   \n",
       "max        100.000000      100.000000      100.000000       100.00000   \n",
       "\n",
       "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
       "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
       "mean        20.278165       16.169432        10.955713         9.953948   \n",
       "std         26.108110       24.845032        22.906263        21.775652   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         0.000000         0.000000   \n",
       "50%         10.000000        5.000000         0.000000         0.000000   \n",
       "75%         25.000000       20.000000        10.000000        10.000000   \n",
       "max        100.000000      100.000000       100.000000       100.000000   \n",
       "\n",
       "       ConvertedCompYearly        JobSat  \n",
       "count         2.343500e+04  29126.000000  \n",
       "mean          8.615529e+04      6.935041  \n",
       "std           1.867570e+05      2.088259  \n",
       "min           1.000000e+00      0.000000  \n",
       "25%           3.271200e+04      6.000000  \n",
       "50%           6.500000e+04      7.000000  \n",
       "75%           1.079715e+05      8.000000  \n",
       "max           1.625660e+07     10.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate basic statistics for numerical columns\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Country' column:\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Identify inconsistent or irrelevant entries in the 'Country' column\n",
    "print(\"Unique values in 'Country' column:\")\n",
    "print(df['Country'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts in 'Country' column:\n",
      "Country\n",
      "United States of America                                11095\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "                                                        ...  \n",
      "Micronesia, Federated States of...                          1\n",
      "Nauru                                                       1\n",
      "Chad                                                        1\n",
      "Djibouti                                                    1\n",
      "Solomon Islands                                             1\n",
      "Name: count, Length: 185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check value counts to identify less frequent or potentially problematic entries\n",
    "\n",
    "print(\"\\nValue counts in 'Country' column:\")\n",
    "print(df['Country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Country' after standardization:\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "\n",
    "# Example: Standardize 'Country' column\n",
    "country_mapping = {\n",
    "    'USA': 'United States',\n",
    "    'U.S.A.': 'United States',\n",
    "    'United Stated': 'United States',  # Example typo\n",
    "    'UK': 'United Kingdom',\n",
    "    'England': 'United Kingdom', # Example if needed.\n",
    "    # Add more mappings as needed based on your dataset\n",
    "}\n",
    "\n",
    "df['Country'] = df['Country'].replace(country_mapping)\n",
    "\n",
    "# Example: Standardize 'EdLevel' column\n",
    "edlevel_mapping = {\n",
    "    'Bachelor’s degree (BA, BS, B.Eng., etc.)': 'Bachelor\\'s degree',\n",
    "    'Master’s degree (MA, MS, M.Eng., MBA, etc.)': 'Master\\'s degree',\n",
    "    'Some college/university study without earning a degree': 'Some college/university',\n",
    "    'Associate degree': 'Associate degree',\n",
    "    'Professional degree (JD, MD, etc.)': 'Professional degree',\n",
    "    'Other doctoral degree (Ph.D., Ed.D., etc.)': 'Doctoral degree',\n",
    "    'Primary/elementary school': 'Primary school',\n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 'Secondary school',\n",
    "    'I never completed any formal education': 'No formal education'\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Unique values in 'Country' after standardization:\")\n",
    "print(df['Country'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'EdLevel' after standardization:\n",
      "['Primary school' 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)'\n",
      " 'Some college/university' 'Secondary school'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else' nan]\n"
     ]
    }
   ],
   "source": [
    "# Standardize entries in columns like EdLevel by mapping inconsistent values to a consistent format.\n",
    "#\n",
    "\n",
    "df['EdLevel'] = df['EdLevel'].replace(edlevel_mapping)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nUnique values in 'EdLevel' after standardization:\")\n",
    "print(df['EdLevel'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age RemoteWork  \\\n",
      "0           1  I am a developer by profession  Under 18 years old     Remote   \n",
      "1           2  I am a developer by profession     35-44 years old     Remote   \n",
      "2           3  I am a developer by profession     45-54 years old     Remote   \n",
      "3           4           I am learning to code     18-24 years old        NaN   \n",
      "4           5  I am a developer by profession     18-24 years old        NaN   \n",
      "\n",
      "    Check                                   CodingActivities  \\\n",
      "0  Apples                                              Hobby   \n",
      "1  Apples  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Apples  Hobby;Contribute to open-source projects;Other...   \n",
      "3  Apples                                                NaN   \n",
      "4  Apples                                                NaN   \n",
      "\n",
      "                                           EdLevel  \\\n",
      "0                                   Primary school   \n",
      "1     Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2  Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3                          Some college/university   \n",
      "4                                 Secondary school   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  \\\n",
      "0                                                NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial   \n",
      "4  Technical documentation;Blogs;Written Tutorial...   \n",
      "\n",
      "                                             TechDoc YearsCode YearsCodePro  \\\n",
      "0                                                NaN       NaN          NaN   \n",
      "1  API document(s) and/or SDK document(s);User gu...        20           17   \n",
      "2  API document(s) and/or SDK document(s);User gu...        37           27   \n",
      "3                                                NaN         4          NaN   \n",
      "4  API document(s) and/or SDK document(s);User gu...         9          NaN   \n",
      "\n",
      "                 DevType OrgSize PurchaseInfluence BuyNewTool BuildvsBuy  \\\n",
      "0                    NaN     NaN               NaN        NaN        NaN   \n",
      "1  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
      "2   Developer Experience     NaN               NaN        NaN        NaN   \n",
      "3  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
      "4  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
      "\n",
      "  TechEndorse                                            Country Currency  \n",
      "0         NaN                           United States of America      NaN  \n",
      "1         NaN  United Kingdom of Great Britain and Northern I...      NaN  \n",
      "2         NaN  United Kingdom of Great Britain and Northern I...      NaN  \n",
      "3         NaN                                             Canada      NaN  \n",
      "4         NaN                                             Norway      NaN  \n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# One-hot encode the 'Employment' column\n",
    "df_encoded = pd.get_dummies(df, columns=['Employment'])\n",
    "\n",
    "# Display the encoded DataFrame (first few columns)\n",
    "print(df_encoded.iloc[:, :20].head())  # Displaying a limited number of columns for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Age</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>Check</th>\n",
       "      <th>CodingActivities</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>LearnCode</th>\n",
       "      <th>LearnCodeOnline</th>\n",
       "      <th>TechDoc</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>DevType</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>PurchaseInfluence</th>\n",
       "      <th>BuyNewTool</th>\n",
       "      <th>BuildvsBuy</th>\n",
       "      <th>TechEndorse</th>\n",
       "      <th>Country</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Under 18 years old</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby</td>\n",
       "      <td>Primary school</td>\n",
       "      <td>Books / Physical media</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>35-44 years old</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>API document(s) and/or SDK document(s);User gu...</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>Developer, full-stack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>45-54 years old</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>API document(s) and/or SDK document(s);User gu...</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>Developer Experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am learning to code</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some college/university</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Stack Overflow;How-to videos;Interactive tutorial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developer, full-stack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secondary school</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Technical documentation;Blogs;Written Tutorial...</td>\n",
       "      <td>API document(s) and/or SDK document(s);User gu...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Developer, full-stack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResponseId                      MainBranch                 Age RemoteWork  \\\n",
       "0           1  I am a developer by profession  Under 18 years old     Remote   \n",
       "1           2  I am a developer by profession     35-44 years old     Remote   \n",
       "2           3  I am a developer by profession     45-54 years old     Remote   \n",
       "3           4           I am learning to code     18-24 years old        NaN   \n",
       "4           5  I am a developer by profession     18-24 years old        NaN   \n",
       "\n",
       "    Check                                   CodingActivities  \\\n",
       "0  Apples                                              Hobby   \n",
       "1  Apples  Hobby;Contribute to open-source projects;Other...   \n",
       "2  Apples  Hobby;Contribute to open-source projects;Other...   \n",
       "3  Apples                                                NaN   \n",
       "4  Apples                                                NaN   \n",
       "\n",
       "                                           EdLevel  \\\n",
       "0                                   Primary school   \n",
       "1     Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       "2  Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
       "3                          Some college/university   \n",
       "4                                 Secondary school   \n",
       "\n",
       "                                           LearnCode  \\\n",
       "0                             Books / Physical media   \n",
       "1  Books / Physical media;Colleague;On the job tr...   \n",
       "2  Books / Physical media;Colleague;On the job tr...   \n",
       "3  Other online resources (e.g., videos, blogs, f...   \n",
       "4  Other online resources (e.g., videos, blogs, f...   \n",
       "\n",
       "                                     LearnCodeOnline  \\\n",
       "0                                                NaN   \n",
       "1  Technical documentation;Blogs;Books;Written Tu...   \n",
       "2  Technical documentation;Blogs;Books;Written Tu...   \n",
       "3  Stack Overflow;How-to videos;Interactive tutorial   \n",
       "4  Technical documentation;Blogs;Written Tutorial...   \n",
       "\n",
       "                                             TechDoc YearsCode YearsCodePro  \\\n",
       "0                                                NaN       NaN          NaN   \n",
       "1  API document(s) and/or SDK document(s);User gu...        20           17   \n",
       "2  API document(s) and/or SDK document(s);User gu...        37           27   \n",
       "3                                                NaN         4          NaN   \n",
       "4  API document(s) and/or SDK document(s);User gu...         9          NaN   \n",
       "\n",
       "                 DevType OrgSize PurchaseInfluence BuyNewTool BuildvsBuy  \\\n",
       "0                    NaN     NaN               NaN        NaN        NaN   \n",
       "1  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
       "2   Developer Experience     NaN               NaN        NaN        NaN   \n",
       "3  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
       "4  Developer, full-stack     NaN               NaN        NaN        NaN   \n",
       "\n",
       "  TechEndorse                                            Country Currency  \n",
       "0         NaN                           United States of America      NaN  \n",
       "1         NaN  United Kingdom of Great Britain and Northern I...      NaN  \n",
       "2         NaN  United Kingdom of Great Britain and Northern I...      NaN  \n",
       "3         NaN                                             Canada      NaN  \n",
       "4         NaN                                             Norway      NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the encoded DataFrame (first few columns)\n",
    "#\n",
    "df_encoded.iloc[:, :20].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the highest number of missing values:\n",
      "AINextMuch less integrated       64289\n",
      "AINextLess integrated            63082\n",
      "AINextNo change                  52939\n",
      "AINextMuch more integrated       51999\n",
      "EmbeddedAdmired                  48704\n",
      "EmbeddedWantToWorkWith           47837\n",
      "EmbeddedHaveWorkedWith           43223\n",
      "ConvertedCompYearly              42002\n",
      "AIToolNot interested in Using    41023\n",
      "AINextMore integrated            41009\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Sort the missing values in descending order\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "\n",
    "# Display the columns with the highest number of missing values\n",
    "print(\"Columns with the highest number of missing values:\")\n",
    "print(missing_values_sorted.head(10))  # Display the top 10 columns (adjust as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ConvertedCompYearly' after imputation: 0\n",
      "WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1544/3751673557.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ConvertedCompYearly'].fillna(median_comp, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Impute missing values in 'ConvertedCompYearly' with the median\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df['ConvertedCompYearly'].fillna(median_comp, inplace=True)\n",
    "\n",
    "# Verify the imputation\n",
    "print(f\"Number of missing values in 'ConvertedCompYearly' after imputation: {df['ConvertedCompYearly'].isnull().sum()}\")\n",
    "\n",
    "# Example: Impute missing values in another numerical column with the mean (if applicable)\n",
    "# Assuming 'WorkWeekHrs' is a numerical column with missing values\n",
    "if 'WorkWeekHrs' in df.columns and pd.api.types.is_numeric_dtype(df['WorkWeekHrs']):\n",
    "    mean_workweek = df['WorkWeekHrs'].mean()\n",
    "    df['WorkWeekHrs'].fillna(mean_workweek, inplace=True)\n",
    "    print(f\"Number of missing values in 'WorkWeekHrs' after imputation: {df['WorkWeekHrs'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ConvertedCompYearly' after imputation: 0\n",
      "WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Assign the Result Back to the Column (Recommended)\n",
    "\n",
    "# Impute missing values in 'ConvertedCompYearly' with the median\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(median_comp)  # Assign the result back\n",
    "\n",
    "# Verify the imputation\n",
    "print(f\"Number of missing values in 'ConvertedCompYearly' after imputation: {df['ConvertedCompYearly'].isnull().sum()}\")\n",
    "\n",
    "# Example: Impute missing values in another numerical column with the mean (if applicable)\n",
    "if 'WorkWeekHrs' in df.columns and pd.api.types.is_numeric_dtype(df['WorkWeekHrs']):\n",
    "    mean_workweek = df['WorkWeekHrs'].mean()\n",
    "    df['WorkWeekHrs'] = df['WorkWeekHrs'].fillna(mean_workweek)  # Assign the result back\n",
    "    print(f\"Number of missing values in 'WorkWeekHrs' after imputation: {df['WorkWeekHrs'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'ConvertedCompYearly' after imputation: 0\n",
      "WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\n"
     ]
    }
   ],
   "source": [
    "# Solution 2: Use df.fillna({col: value}, inplace=True) (Less Common)\n",
    "\n",
    "# Impute missing values in 'ConvertedCompYearly' with the median\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df.fillna({'ConvertedCompYearly': median_comp}, inplace=True)  # Using the dictionary approach\n",
    "\n",
    "# Verify the imputation\n",
    "print(f\"Number of missing values in 'ConvertedCompYearly' after imputation: {df['ConvertedCompYearly'].isnull().sum()}\")\n",
    "\n",
    "# Example: Impute missing values in another numerical column with the mean (if applicable)\n",
    "if 'WorkWeekHrs' in df.columns and pd.api.types.is_numeric_dtype(df['WorkWeekHrs']):\n",
    "    mean_workweek = df['WorkWeekHrs'].mean()\n",
    "    df.fillna({'WorkWeekHrs': mean_workweek}, inplace=True)\n",
    "    print(f\"Number of missing values in 'WorkWeekHrs' after imputation: {df['WorkWeekHrs'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"WorkWeekHrs column not found, or not numeric. Skipping mean imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'RemoteWork' after imputation: 0\n",
      "Number of missing values in 'EdLevel' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Impute missing values in 'RemoteWork' with the most frequent value\n",
    "if 'RemoteWork' in df.columns:\n",
    "    most_frequent_remote = df['RemoteWork'].mode()[0]\n",
    "    df['RemoteWork'] = df['RemoteWork'].fillna(most_frequent_remote)\n",
    "\n",
    "    # Verify the imputation\n",
    "    print(f\"Number of missing values in 'RemoteWork' after imputation: {df['RemoteWork'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"RemoteWork column not found.\")\n",
    "\n",
    "# Example: Impute missing values in another categorical column (if applicable)\n",
    "# Assuming 'EdLevel' is a categorical column with missing values\n",
    "if 'EdLevel' in df.columns:\n",
    "    most_frequent_edlevel = df['EdLevel'].mode()[0]\n",
    "    df['EdLevel'] = df['EdLevel'].fillna(most_frequent_edlevel)\n",
    "\n",
    "    # Verify the imputation\n",
    "    print(f\"Number of missing values in 'EdLevel' after imputation: {df['EdLevel'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"EdLevel column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Normalized\n",
      "0              65000.0                        0.003998\n",
      "1              65000.0                        0.003998\n",
      "2              65000.0                        0.003998\n",
      "3              65000.0                        0.003998\n",
      "4              65000.0                        0.003998\n",
      "\n",
      "Min of NormalizedCompYearly: 0.0\n",
      "Max of NormalizedCompYearly: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Handle missing values in 'ConvertedCompYearly' (replace with median)\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(median_comp)\n",
    "\n",
    "# Apply Min-Max Scaling to 'ConvertedCompYearly'\n",
    "scaler = MinMaxScaler()\n",
    "df['ConvertedCompYearly_Normalized'] = scaler.fit_transform(df[['ConvertedCompYearly']])\n",
    "\n",
    "# Display the normalized column (first few rows)\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_Normalized']].head())\n",
    "\n",
    "# Optionally, check the min and max of the normalized column\n",
    "print(f\"\\nMin of NormalizedCompYearly: {df['ConvertedCompYearly_Normalized'].min()}\")\n",
    "print(f\"Max of NormalizedCompYearly: {df['ConvertedCompYearly_Normalized'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
      "0              65000.0                11.082158\n",
      "1              65000.0                11.082158\n",
      "2              65000.0                11.082158\n",
      "3              65000.0                11.082158\n",
      "4              65000.0                11.082158\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Handle missing values in 'ConvertedCompYearly' (replace with median)\n",
    "median_comp = df['ConvertedCompYearly'].median()\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(median_comp)\n",
    "\n",
    "# Apply log transformation to 'ConvertedCompYearly'\n",
    "# Add a small constant to avoid log(0) errors\n",
    "df['ConvertedCompYearly_Log'] = np.log(df['ConvertedCompYearly'] + 1)\n",
    "\n",
    "# Display the transformed column (first few rows)\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_Log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  YearsCodePro ExperienceLevel\n",
      "0          NaN         Unknown\n",
      "1           17          Senior\n",
      "2           27          Senior\n",
      "3          NaN         Unknown\n",
      "4          NaN         Unknown\n",
      "5          NaN         Unknown\n",
      "6            7          Senior\n",
      "7          NaN         Unknown\n",
      "8          NaN         Unknown\n",
      "9           11          Senior\n",
      "\n",
      "Experience Level Counts:\n",
      "ExperienceLevel\n",
      "Senior          34589\n",
      "Unknown         16733\n",
      "Intermediate    11476\n",
      "Junior           2639\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Function to categorize experience level\n",
    "def categorize_experience(years):\n",
    "    if pd.isnull(years):\n",
    "        return 'Unknown'\n",
    "    try:\n",
    "        years = float(years)\n",
    "        if years < 2:\n",
    "            return 'Junior'\n",
    "        elif years < 5:\n",
    "            return 'Intermediate'\n",
    "        else:\n",
    "            return 'Senior'\n",
    "    except ValueError:\n",
    "        return 'Unknown'  # Handle non-numeric entries\n",
    "\n",
    "# Create the ExperienceLevel column\n",
    "df['ExperienceLevel'] = df['YearsCodePro'].apply(categorize_experience)\n",
    "\n",
    "# Display the new column and 'YearsCodePro'\n",
    "print(df[['YearsCodePro', 'ExperienceLevel']].head(10))\n",
    "\n",
    "# Optionally, check the counts of each category\n",
    "print(\"\\nExperience Level Counts:\")\n",
    "print(df['ExperienceLevel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
