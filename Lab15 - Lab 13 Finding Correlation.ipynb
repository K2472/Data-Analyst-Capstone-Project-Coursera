{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Correlation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will work with a cleaned dataset to perform exploratory data analysis (EDA). You will examine the distribution of the data, identify outliers, and determine the correlation between different columns in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify the distribution of compensation data in the dataset.\n",
    "\n",
    "- Remove outliers to refine the dataset.\n",
    "\n",
    "- Identify correlations between various features in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Install and Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the given URL\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Analyze and Visualize Compensation Distribution</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Plot the distribution and histogram for `ConvertedCompYearly` to examine the spread of yearly compensation among respondents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 3: Analyze and Visualize Compensation Distribution\n",
    "\n",
    "# Check if 'ConvertedCompYearly' column exists\n",
    "if 'ConvertedCompYearly' not in df.columns:\n",
    "    print(\"ConvertedCompYearly column not found in the dataset.\")\n",
    "else:\n",
    "    # Distribution Plot (KDE Plot)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.kdeplot(df['ConvertedCompYearly'], fill=True)\n",
    "    plt.title('Distribution of Yearly Compensation (ConvertedCompYearly)')\n",
    "    plt.xlabel('Yearly Compensation (USD)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(df['ConvertedCompYearly'], bins=50, edgecolor='black')  # Adjust bins as needed\n",
    "    plt.title('Histogram of Yearly Compensation (ConvertedCompYearly)')\n",
    "    plt.xlabel('Yearly Compensation (USD)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 4: Calculate Median Compensation for Full-Time Employees</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Filter the data to calculate the median compensation for respondents whose employment status is \"Employed, full-time.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 4: Calculate Median Compensation for Full-Time Employees\n",
    "\n",
    "# Check if 'Employment' and 'ConvertedCompYearly' columns exist\n",
    "if 'Employment' not in df.columns or 'ConvertedCompYearly' not in df.columns:\n",
    "    print(\"One or both of 'Employment' and 'ConvertedCompYearly' columns not found in the dataset.\")\n",
    "else:\n",
    "    # Filter for full-time employees\n",
    "    full_time_employees = df[df['Employment'] == 'Employed, full-time']\n",
    "\n",
    "    # Calculate median compensation\n",
    "    median_compensation = full_time_employees['ConvertedCompYearly'].median()\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Median Compensation for Full-Time Employees: ${median_compensation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 5: Analyzing Compensation Range and Distribution by Country</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the range of compensation in the ConvertedCompYearly column by analyzing differences across countries. Use box plots to compare the compensation distributions for each country to identify variations and anomalies within each region, providing insights into global compensation trends.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 5: Analyzing Compensation Range and Distribution by Country\n",
    "\n",
    "# Check if 'Country' and 'ConvertedCompYearly' columns exist\n",
    "if 'Country' not in df.columns or 'ConvertedCompYearly' not in df.columns:\n",
    "    print(\"One or both of 'Country' and 'ConvertedCompYearly' columns not found in the dataset.\")\n",
    "else:\n",
    "    # Filter out countries with very few respondents to improve readability\n",
    "    country_counts = df['Country'].value_counts()\n",
    "    valid_countries = country_counts[country_counts > 50].index  # Adjust the threshold as needed\n",
    "    df_filtered = df[df['Country'].isin(valid_countries)]\n",
    "\n",
    "    # Create box plots for compensation by country\n",
    "    plt.figure(figsize=(18, 10))  # Adjust figure size for better visualization\n",
    "    sns.boxplot(x='Country', y='ConvertedCompYearly', data=df_filtered)\n",
    "    plt.title('Compensation Distribution by Country')\n",
    "    plt.xlabel('Country')\n",
    "    plt.ylabel('Yearly Compensation (USD)')\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate country labels for readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 6: Removing Outliers from the Dataset</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Create a new DataFrame by removing outliers from the `ConvertedCompYearly` column to get a refined dataset for correlation analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 6: Removing Outliers from the Dataset\n",
    "\n",
    "# Check if 'ConvertedCompYearly' column exists\n",
    "if 'ConvertedCompYearly' not in df.columns:\n",
    "    print(\"ConvertedCompYearly column not found in the dataset.\")\n",
    "else:\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df['ConvertedCompYearly'].quantile(0.25)\n",
    "    Q3 = df['ConvertedCompYearly'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Determine upper and lower bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Create a new DataFrame without outliers\n",
    "    df_no_outliers = df[(df['ConvertedCompYearly'] >= lower_bound) & (df['ConvertedCompYearly'] <= upper_bound)]\n",
    "\n",
    "    # Print the size of the original and new DataFrames\n",
    "    print(f\"Original DataFrame size: {len(df)}\")\n",
    "    print(f\"DataFrame size after removing outliers: {len(df_no_outliers)}\")\n",
    "\n",
    "    # Optional: Display the first few rows of the new DataFrame\n",
    "    print(\"\\nDataFrame without outliers (first 5 rows):\")\n",
    "    print(df_no_outliers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 6: Removing Outliers from the Dataset\n",
    "\n",
    "# Check if 'ConvertedCompYearly' column exists\n",
    "if 'ConvertedCompYearly' not in df.columns:\n",
    "    print(\"ConvertedCompYearly column not found in the dataset.\")\n",
    "else:\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df['ConvertedCompYearly'].quantile(0.25)\n",
    "    Q3 = df['ConvertedCompYearly'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Determine upper and lower bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Create a new DataFrame without outliers\n",
    "    df_no_outliers = df[\n",
    "        (df['ConvertedCompYearly'] >= lower_bound)\n",
    "        & (df['ConvertedCompYearly'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    # Print the size of the original and new DataFrames\n",
    "    print(f\"Original DataFrame size: {len(df)}\")\n",
    "    print(f\"DataFrame size after removing outliers: {len(df_no_outliers)}\")\n",
    "\n",
    "    # Optional: Display the first few rows of the new DataFrame\n",
    "    print(\"\\nDataFrame without outliers (first 5 rows):\")\n",
    "    print(df_no_outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 7: Finding Correlations Between Key Variables</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Calculate correlations between `ConvertedCompYearly`, `WorkExp`, and `JobSatPoints_1`. Visualize these correlations with a heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 7: Finding Correlations Between Key Variables\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['ConvertedCompYearly', 'WorkExp', 'JobSatPoints_1']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    print(f\"Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    # Calculate correlations\n",
    "    correlation_matrix = df[['ConvertedCompYearly', 'WorkExp', 'JobSatPoints_1']].corr()\n",
    "\n",
    "    # Visualize correlations with a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 8: Scatter Plot for Correlations</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Create scatter plots to examine specific correlations between `ConvertedCompYearly` and `WorkExp`, as well as between `ConvertedCompYearly` and `JobSatPoints_1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "# Step 8: Scatter Plot for Correlations\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['ConvertedCompYearly', 'WorkExp', 'JobSatPoints_1']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    print(f\"Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    # Scatter plot: ConvertedCompYearly vs. WorkExp\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='WorkExp', y='ConvertedCompYearly', data=df)\n",
    "    plt.title('Scatter Plot: Yearly Compensation vs. Work Experience')\n",
    "    plt.xlabel('Work Experience (Years)')\n",
    "    plt.ylabel('Yearly Compensation (USD)')\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter plot: ConvertedCompYearly vs. JobSatPoints_1\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='JobSatPoints_1', y='ConvertedCompYearly', data=df)\n",
    "    plt.title('Scatter Plot: Yearly Compensation vs. Job Satisfaction')\n",
    "    plt.xlabel('Job Satisfaction (Points)')\n",
    "    plt.ylabel('Yearly Compensation (USD)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you practiced essential skills in correlation analysis by:\n",
    "\n",
    "- Examining the distribution of yearly compensation with histograms and box plots.\n",
    "- Detecting and removing outliers from compensation data.\n",
    "- Calculating correlations between key variables such as compensation, work experience, and job satisfaction.\n",
    "- Visualizing relationships with scatter plots and heatmaps to gain insights into the associations between these features.\n",
    "\n",
    "By following these steps, you have developed a solid foundation for analyzing relationships within the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors:\n",
    "Ayushi Jain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors:\n",
    "- Rav Ahuja\n",
    "- Lakshmi Holla\n",
    "- Malika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "cd002f216a8f007d424ab00c7f1ce2f3922b5f7953054f2920a8ed91b89e1556"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
